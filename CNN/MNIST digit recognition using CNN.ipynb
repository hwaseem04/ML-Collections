{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9538537",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "- Input : 28 * 28 * 1\n",
    "- Convolution layer 1 with 32 filters - Output: 28 * 28 * 32 (32 filter maps)\n",
    "- Max pooling with 2 * 2 matrix - Output: 14 * 14 * 32 (Shrinked)\n",
    "- Convolution layer 2 with 64 filters of depth 32 - Output: 14 * 14 * 64\n",
    "- Max pooling with 2 * 2 matrix - Output: 7 * 7 * 64\n",
    "- FC1 \n",
    "- FC2 \n",
    "- Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54cbc0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadwaseem/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/muhammadwaseem/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <CAE66874-17C2-35C9-9C4D-6BA9770AF17F> /Users/muhammadwaseem/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <459875AA-DE2C-366B-9C44-90D4B3887080> /Users/muhammadwaseem/miniconda3/envs/torch/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90394714",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda754e",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f09196ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './'\n",
    "mnist_data = torchvision.datasets.MNIST(root = image_path,\n",
    "                                        train = True,\n",
    "                                        transform = transforms.ToTensor(),\n",
    "                                        download = True)\n",
    "mnist_test_data = torchvision.datasets.MNIST(root = image_path, \n",
    "                                             train = False,\n",
    "                                             transform = transforms.ToTensor(),\n",
    "                                             download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a391c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_valid_dataset = Subset(mnist_data, torch.arange(10000)) \n",
    "mnist_train_dataset = Subset(mnist_data, torch.arange(10000, len(mnist_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19dc898d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_valid_dataset[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1da3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = TensorDataset(mnist_data.data, mnist_data.targets)\n",
    "# mnist_validation = TensorDataset(dataset[:10000][0],dataset[:10000][1])\n",
    "# mnist_train = TensorDataset(dataset[10000:][0],dataset[10000:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d01cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "torch.manual_seed(1) # To produce same set of 64 batch on each time when we run \n",
    "data = DataLoader(mnist_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Why to shuffle validation?? What is the difference if I dont batch and calculate validation performance\n",
    "# entirely on the validation set after each epoch ?\n",
    "data_vl = DataLoader(mnist_valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62bc869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_vl))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8637465b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1af417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  (relu4): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('conv1', \n",
    "                 nn.Conv2d( in_channels=1, out_channels=32,\n",
    "                 kernel_size=5, padding=2)) # Padding=2 which makes it as `same mode`\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=2)) # default: stride=kernel_size=2\n",
    "model.add_module('conv2',\n",
    "                 nn.Conv2d( in_channels=32, out_channels=64,\n",
    "                 kernel_size=5, padding=2))\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))\n",
    "model.add_module('flatten', nn.Flatten(1))\n",
    "model.add_module('fc1', nn.Linear(3136, 1024)) # 3136 is determined by inspecting the output of prev layer :)\n",
    "model.add_module('relu3', nn.ReLU())\n",
    "# DROPOUT: leave half of the neuron units while training on each iteration. But batch wise or epoch wise?\n",
    "model.add_module('dropout', nn.Dropout(p=0.5))  # Inverse dropout will be carried out during training phase\n",
    "model.add_module('fc2', nn.Linear(1024, 10))\n",
    "model.add_module('relu4', nn.ReLU())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da84926",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873a2fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((64,1, 28, 28), device=mps_device)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b5352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc170603",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57112a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Accuracy - train: 0.671180009841919, validation: 0.7034000158309937\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m---> 48\u001b[0m train_loss, train_accuracy, validation_loss, validation_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_vl\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, epoch, data, data_vl)\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m train_loss[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m x_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m soft_pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;66;03m#torch.softmax(pred, axis=1) # why is it not done?\u001b[39;00m\n\u001b[1;32m     22\u001b[0m is_crt \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39margmax(soft_pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y_batch)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, epoch, data, data_vl):\n",
    "    train_loss = [0] * epoch\n",
    "    train_accuracy = [0] * epoch\n",
    "    validation_loss = [0] * epoch\n",
    "    validation_accuracy = [0] * epoch\n",
    "    for i in range(epoch):\n",
    "        model.train() # to ENABLE dropout while training\n",
    "        for x_batch, y_batch in data:\n",
    "            x_batch = x_batch.to(mps_device)\n",
    "            y_batch = y_batch.to(mps_device)\n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_loss[i] += loss.item() * x_batch.size(0)\n",
    "            soft_pred = torch.softmax(pred, axis=1) # why is it not done?\n",
    "            \n",
    "            is_crt = (torch.argmax(soft_pred, dim=1) == y_batch).to(torch.float32).sum().cpu()\n",
    "            train_accuracy[i] += is_crt\n",
    "\n",
    "        train_loss[i] /= len(data.dataset)\n",
    "        train_accuracy[i] /= len(data.dataset)\n",
    "        \n",
    "        model.eval() # to AVOID dropout while inference\n",
    "        \n",
    "        # Why dont we calculate the validation error/accuracy after an entire epoch? Is performance a reason?\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in data_vl:\n",
    "                x_batch = x_batch.to(mps_device)\n",
    "                y_batch = y_batch.to(mps_device)\n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                validation_loss[i] += loss.item() * x_batch.size(0)\n",
    "                soft_pred = torch.softmax(pred, axis=1) # why is it not done?\n",
    "                is_crt = (torch.argmax(soft_pred, dim=1) == y_batch).sum().to(torch.float32).cpu()\n",
    "                validation_accuracy[i] += is_crt\n",
    "            validation_loss[i] /= len(data_vl.dataset)\n",
    "            validation_accuracy[i] /= len(data_vl.dataset)\n",
    "        print(f\"Epoch: {i+1}, Accuracy - train: {train_accuracy[i]}, validation: {validation_accuracy[i]}\")\n",
    "    return train_loss, train_accuracy, validation_loss, validation_accuracy\n",
    "\n",
    "torch.manual_seed(1)\n",
    "epoch = 20\n",
    "train_loss, train_accuracy, validation_loss, validation_accuracy = train(model, epoch, data, data_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58421775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epoch, train_loss, marker='-o', label=\"Train Loss\")\n",
    "plt.plot(epoch, validation_loss, marker='--<', label=\"Validation Loss\")\n",
    "plt.xlabel(\"$Epoch$\")\n",
    "plt.ylabel(\"$Loss$\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch, train_accuracy, marker='-o', label=\"Train Accuracy\")\n",
    "plt.plot(epoch, Validation_accuracy, marker='--<', label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"$Epoch$\")\n",
    "plt.ylabel(\"$Accuracy$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac6101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
